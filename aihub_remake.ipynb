{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  \n",
    "import torch\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from IPython.display import display, Audio\n",
    "import librosa\n",
    "import random\n",
    "def ms2samples(time, rate):\n",
    "    return int((time/1000)*rate)\n",
    "\n",
    "def samples2ms(sample,rate):\n",
    "    return int((sample/rate)*1000)\n",
    "    \n",
    "def graph_n_play(y,sr):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.waveplot(y, sr=sr)\n",
    "    plt.show()\n",
    "    ipd.display(ipd.Audio(y,rate = sr))\n",
    "def linear_n_play(audio_path):\n",
    "    # y, sr = sf.read(audio_path)\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    fig, ax = plt.subplots()\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, y_axis='linear', x_axis='time',\n",
    "                                   sr=sr, ax=ax)\n",
    "    ax.set(title='Linear-frequency power spectrogram')\n",
    "    ax.label_outer()\n",
    "    display(Audio(y,rate=sr))\n",
    "    plt.show()\n",
    "def recursive_list_files(path, file_extension=\".wav\"):\n",
    "    \"\"\"Recursively lists all files in a directory and its subdirectories\"\"\"\n",
    "    files = []\n",
    "    for dirpath, dirnames, filenames in walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(file_extension):\n",
    "                files.append(join(dirpath, filename))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213989"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all file in real data\n",
    "\n",
    "real_data = recursive_list_files(\"/dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs\")\n",
    "len(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all file in fake data\n",
    "fake_data = recursive_list_files(\"/dataa/Dataset/Korean_Fake/Wav_voice\")\n",
    "len(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213989/213989 [28:29<00:00, 125.19it/s]\n",
      "100%|██████████| 32600/32600 [10:06<00:00, 53.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           spid                    utt  \\\n",
       "0   05MSTK0045   05MSTK0045_06647.wav   \n",
       "0   05MSTK0045   05MSTK0045_06821.wav   \n",
       "0   05MSTK0045   05MSTK0045_07527.wav   \n",
       "0   05MSTK0045   05MSTK0045_07359.wav   \n",
       "0   05MSTK0045   05MSTK0045_07426.wav   \n",
       "..         ...                    ...   \n",
       "0   07MAJM0028  07MAJM0028_000019.wav   \n",
       "0   07MAJM0028  07MAJM0028_000003.wav   \n",
       "0   07MAJM0028  07MAJM0028_000101.wav   \n",
       "0   07MAJM0028  07MAJM0028_000188.wav   \n",
       "0   07MAJM0028  07MAJM0028_000094.wav   \n",
       "\n",
       "                                                 path label  \n",
       "0   /dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs...  real  \n",
       "0   /dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs...  real  \n",
       "0   /dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs...  real  \n",
       "0   /dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs...  real  \n",
       "0   /dataa/aisrc1/Dataset/Speech/AIHub_Studio/wavs...  real  \n",
       "..                                                ...   ...  \n",
       "0   /dataa/Dataset/Korean_Fake/Wav_voice/07MAJM002...  fake  \n",
       "0   /dataa/Dataset/Korean_Fake/Wav_voice/07MAJM002...  fake  \n",
       "0   /dataa/Dataset/Korean_Fake/Wav_voice/07MAJM002...  fake  \n",
       "0   /dataa/Dataset/Korean_Fake/Wav_voice/07MAJM002...  fake  \n",
       "0   /dataa/Dataset/Korean_Fake/Wav_voice/07MAJM002...  fake  \n",
       "\n",
       "[246589 rows x 4 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"spid\",\"utt\",\"path\",\"label\"])\n",
    "for i in tqdm(range(len(real_data))):\n",
    "    df = pd.concat([df,pd.DataFrame({\"spid\":real_data[i].split(\"/\")[-2],\"utt\":real_data[i].split(\"/\")[-1],\"path\":real_data[i],\"label\":\"real\"},index=[0])],axis=0)\n",
    "\n",
    "for i in tqdm(range(len(fake_data))):\n",
    "    df = pd.concat([df,pd.DataFrame({\"spid\":fake_data[i].split(\"/\")[-2].split(\"_\")[0],\"utt\":fake_data[i].split(\"/\")[-1],\"path\":fake_data[i],\"label\":\"fake\"},index=[0])],axis=0)\n",
    "    \n",
    "df.headff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = df[:213989]\n",
    "fake_df = df[213989:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = real_df.drop(real_df.sample(frac=.7).index)\n",
    "real_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['07MAJM0028', '07MAJM0028_000169.wav',\n",
       "       '/dataa/Dataset/Korean_Fake/Wav_voice/07MAJM0028_Voice_data/07MAJM0028_000169.wav',\n",
       "       'fake'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test dataframe\n",
    "df.loc[(df[\"spid\"]==\"07MAJM0028\") & (df[\"label\"]==\"fake\")].sample().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8243, 4), (53405, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.to_csv(\"/dataa/aisrc1/Dataset/Speech/AIHub_Studio/train.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
